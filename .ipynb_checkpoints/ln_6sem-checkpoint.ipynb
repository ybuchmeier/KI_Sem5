{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#!pip install bayesian-optimization\n",
    "#!pip install torch\n",
    "#!pip install pyro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd350be7",
   "metadata": {},
   "source": [
    "|Variable|Erklärung|Anmerkung|\n",
    "|:---|:---|:---|\n",
    "Age|Age of the patient|\n",
    "Sex|Sex of the patient\n",
    "exang|exercise induced angina (1 = yes; 0 = no)|Hat man Engegefühl wenn man Sport macht?\n",
    "caa|number of major vessels (0-3)|weglassen, da Beschreibung uneindeutig, Skala passt auch nicht [0-3] \n",
    "cp|Chest Pain type chest pain type|Value 1: typical angina<br>Value 2: atypical angina<br>Value 3: non-anginal pain<br>Value 4: asymptomatic\n",
    "trtbps|resting blood pressure (in mm Hg): Blutdruck bei Ruhe\n",
    "chol|cholestoral in mg/dl fetched via BMI sensor|Cholesterinspiegel\n",
    "fbs|(fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)|Erhöhter Blutzucker\n",
    "rest_ecg|resting electrocardiographic results|Value 0: normal<br>Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)<br>Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "thalach|maximum heart rate achieved: Puls\n",
    "target|0= less chance of heart attack 1= more chance of heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4132b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Datenset laden\n",
    "# https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset\n",
    "fulldata = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datentypen anpassen\n",
    "cols = [\n",
    "    \"sex\",\n",
    "    \"cp\",\n",
    "    \"fbs\",\n",
    "    \"restecg\",\n",
    "    \"output\"\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "    fulldata[col] = fulldata[col].astype(\"category\")\n",
    "    \n",
    "cols = [\n",
    "    \"exng\"\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "    fulldata[col] = fulldata[col].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5452ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset\n",
    "fulldata = pd.read_csv(\"heart.csv\")\n",
    "#data = fulldata.drop(['cp', 'restecg', 'output'], axis=1)\n",
    "data = fulldata.drop(['output'], axis=1)\n",
    "output = fulldata['output']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "X, y = data, output\n",
    "\n",
    "\n",
    "# split the data into 2 sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9b868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "result_array = []\n",
    "# warum keine precomputed method?\n",
    "methods = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "k = 10\n",
    "for i, element in enumerate(methods):\n",
    "    method = methods[i] \n",
    "    clf = svm.SVC(kernel=method, C=1, random_state=42)\n",
    "    scores = cross_val_score(clf, data, output, cv=k)\n",
    "    result_array.append((scores.max(), method))\n",
    "result_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1faa5",
   "metadata": {},
   "source": [
    "k = 10\n",
    "clf = svm.SVC(kernel=\"linear\", C=1, random_state=42)\n",
    "scores = cross_val_score(clf, data, output, cv=k)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba830db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = svm.SVC(kernel=linear, C=1, random_state=42)\n",
    "#scores = cross_val_score(clf, data, output, cv=k)\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']}]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a SVC and optimize it with a grid search\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "clf.fit(data, output)\n",
    "\n",
    "# get the best estimator\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "clf = svm.SVC(kernel=\"linear\", C=0.0001, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black(C):\n",
    "    # C: SVC hyper parameter to optimize for.\n",
    "    #model = SVC(C = C, kernel=\"linear\" )\n",
    "    model = svm.SVC(kernel=\"linear\", C=C, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #from sklearn.metrics import accuracy_score \n",
    "    #data[\"predicted\"] = model.predict(data) \n",
    "    #f = accuracy_score(y_true = fulldata[\"output\"], y_pred = data[\"predicted\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #f = model.score(X_test, y_test)\n",
    "    #model.fit(X_train_scaled, y_train)\n",
    "    #model.fit(X_train, y_train)\n",
    "    #y_score = model.decision_function(X_test_scaled)\n",
    "    #y_score = model.decision_function(X_test)\n",
    "    #f = roc_auc_score(y_test, y_score)\n",
    "    #y_score = model.decision_function(X_test)\n",
    "    f = model.score(X_train, y_train)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "black(83.34510871314733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbd0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.array(X_train))\n",
    "X_test_scaled = scaler.transform(np.array(X_test))\n",
    "# Define the black box function to optimize.\n",
    "\n",
    "def black_box_function(C):\n",
    "    # C: SVC hyper parameter to optimize for.\n",
    "    #model = SVC(C = C, kernel=\"linear\" )\n",
    "    \n",
    "    model = svm.SVC(kernel=\"linear\", C=C, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #from sklearn.metrics import accuracy_score \n",
    "    #fulldata[\"predicted\"] = model.predict(data) \n",
    "    #f = accuracy_score(y_true = fulldata[\"output\"], y_pred = fulldata[\"predicted\"])\n",
    "    #model.fit(X_train_scaled, y_train)\n",
    "    #model.fit(X_train, y_train)\n",
    "    #y_score = model.decision_function(X_test_scaled)\n",
    "    #y_score = model.decision_function(X_test)\n",
    "    #f = roc_auc_score(y_test, y_score)\n",
    "    #y_score = model.decision_function(X_test)\n",
    "    f = model.score(X_train, y_train)\n",
    "    return f\n",
    "\n",
    "def black_box_functionorigi(C):\n",
    "    # C: SVC hyper parameter to optimize for.\n",
    "    model = SVC(C = C, kernel=\"linear\", random_state=42 )\n",
    "    \n",
    "    #model.fit(X_train_scaled, y_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    #y_score = model.decision_function(X_test_scaled)\n",
    "    y_score = model.decision_function(X_test)\n",
    "    f = roc_auc_score(y_test, y_score)\n",
    "    #y_score = model.decision_function(X_test)\n",
    "    #f = model.score(X_train, y_train)\n",
    "    return f\n",
    "# Set range of C to optimize for.\n",
    "# bayes_opt requires this to be a dictionary.\n",
    "pbounds = {\"C\": [1, 100]}\n",
    "# Create a BayesianOptimization optimizer,\n",
    "# and optimize the given black_box_function.\n",
    "optimizer = BayesianOptimization(f = black_box_function,\n",
    "                                 pbounds = pbounds, verbose = 2,\n",
    "                                 random_state = 1)\n",
    "optimizer.maximize(init_points = 10, n_iter = 10)\n",
    "print(\"Best result: {}; f(x) = {}.\".format(optimizer.max[\"params\"], optimizer.max[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from matplotlib import pyplot as plt\n",
    "# we just use 2 dimensions here because we want to visualize the result\n",
    "\n",
    "model = svm.SVC(kernel='linear', C=1)\n",
    "#svm.SVC(kernel='rbf', C=1, gamma=.7)\n",
    "#models = (clf.fit(data[\"age\"], data[\"output\"]) for clf in models)\n",
    "fitted = model.fit(data[\"age\"], data[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title for the plots\n",
    "titles = ('SVC with linear kernel',\n",
    "          'SVC with RBF kernel')\n",
    "\n",
    "# Set-up 1x2 grid for plotting.\n",
    "fig, sub = plt.subplots(1, 2, figsize=(15, 7))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Petal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944b19a",
   "metadata": {},
   "source": [
    "## False Negatives verringern\n",
    "### Überblick verschaffen\n",
    "Für unseren Anwendungsfall sind False Negatives besonders fatal, weshalb sie möglichst gering sein soll.\n",
    "\n",
    "Als False Negatives werden Ergebnisse bezeichnet, die als fälschlicherweise als negativ bewertet wurden, ob wohl der Test in Wahrheit positiv ist.\n",
    "\n",
    "Zunächst werden die Ausgangs-Werte bestimmt.\n",
    "Anschließend wird die Gewichtung verändert.\n",
    "Dadurch werden die Ergebnisse \"pessimistischer\", also es wird eher ein mögliches Risiko ausgegeben.\n",
    "\n",
    "Die für eine bessere Genauigkeit sind mehr Daten notwendig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(data, suptitle):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(9, 3))\n",
    "    fig.suptitle(suptitle)\n",
    "    \n",
    "    _ = sns.heatmap(data, cmap ='binary', annot = True, fmt=\"d\", ax=ax[0]) \\\n",
    "        .set(xlabel = \"True label\", ylabel = \"Predicted label\")\n",
    "    \n",
    "    _ = sns.heatmap(data / data.sum(), cmap ='binary', annot = True, fmt=\".2%\", ax=ax[1]) \\\n",
    "        .set(xlabel = \"True label\", ylabel = \"Predicted label\")\n",
    "    \n",
    "    # Zusammenaddiert für convenience\n",
    "    float_formatter = \"{:.2%}\".format\n",
    "    print(\"Richtig klassifiziert:\", float_formatter((data[0][0] + data[1][1]) / data.sum()))\n",
    "    print(\"Falsch klassifiziert:\", float_formatter((data[1][0] + data[0][1]) / data.sum()))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_train, clf.predict(X_train)), \"Confusion Matrix mit Trainingsdaten\")\n",
    "plot_confusion_matrix(confusion_matrix(y_test, clf.predict(X_test)), \"Confusion Matrix mit Testdaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25c667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [83.34510871314733], 'kernel': ['linear']}] # C-Wert von vorher übernommen\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "# create a SVC and optimize it with a grid search\n",
    "svc = svm.SVC(class_weight={0: 2.2, 1: 1}) # Gewichtung durch Ausprobieren erhalten.\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "clf.fit(data, output)\n",
    "\n",
    "# get the best estimator\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9f5b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_train, clf.predict(X_train)), \"Confusion Matrix mit Trainingsdaten\")\n",
    "plot_confusion_matrix(confusion_matrix(y_test, clf.predict(X_test)), \"Confusion Matrix mit Testdaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebee6c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
