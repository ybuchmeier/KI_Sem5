{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-worst",
   "metadata": {},
   "source": [
    "Wahlpflichtfach Künstliche Intelligenz II: Praktikum | [Startseite](index.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-theme",
   "metadata": {},
   "source": [
    "# 03 - Testat zu Scikit-learn (sklearn)\n",
    "__Gruppennummer:__ 4\n",
    "\n",
    "__Mitglieder:__\n",
    "- Jan Neitzner\n",
    "- Lukas Hein\n",
    "- Timo Marzok\n",
    "- Yannick Buchmeier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-adjustment",
   "metadata": {},
   "source": [
    "In diesem Testat werden Sie die unterschiedlichen Arbeitsschritte von der Datenvorverarbeitung über die Modell- und Teststrategieauswahl bis hin zur Evaluierung mit Hilfe von Scikit-learn durchführen. Dabei verwenden wir eine leicht modifizierte Variante des [California Housing Datasets](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset). Dieses enthält die folgenden _acht_ Merkmale:\n",
    "- __MedInc:__ Das mittlere Einkommen im Block\n",
    "- __HouseAge:__ Das mittlere Hausalter im Block\n",
    "- __AveRooms:__ Die durchschnittliche Raumanzahl pro Haushalt im Block\n",
    "- __AveBedrms:__ Die durchschnittliche Schlafzimmeranzahl pro Haushalt im Block\n",
    "- __Population:__ Die Bevölkerunganzahl im Block\n",
    "- __AveOccup:__ Die durchschnittliche Anzahl von Personen pro Haushalt im Block\n",
    "- __Latitude:__ Der Breitengrad des Blocks\n",
    "- __Longitude:__ Der Längengrad des Blocks\n",
    "\n",
    "Jedem Datenpunkt ist genau einer Klasse (_low_, _mid-low_, _mid_, _mid-high_, _high_) zugeordnet, die angibt, wie hoch der mittlere Hauswert im Block ist. Jede Klasse enthält ~20% der Datenpunkte.\n",
    "\n",
    "## Aufgabe 0 - Data Understanding\n",
    "__unbenotet__\n",
    "\n",
    "Laden Sie die Daten und machen Sie sich mit ihnen vertraut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('california_housing_data.csv')\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-opening",
   "metadata": {},
   "source": [
    "Eventuell hilft Ihnen auch der folgende Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.pairplot(housing_df, hue=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-drinking",
   "metadata": {},
   "source": [
    "## Aufgabe 1 - Data Preparation (4 Punkte)\n",
    "Die erste Aufgabe ist es den Datensatz fürs maschinelle Lernen vorzubereiten. Dazu sind die folgenden Schritte nötig:\n",
    "- a) Auswahl der Strategie(n) zum Ersetzen der fehlenden Werte\n",
    "- b) Auswahl der Strategie(n) zur Skalierung der Daten\n",
    "- c) Erstellen der Preparation-Pipeline\n",
    "\n",
    "Da das Ersetzen der fehlenden Werte und die Skalierung der Daten in einer `Pipeline` passieren soll, können Sie nur Algorithmen verwenden, die __sklearn__ bereitstellt.\n",
    "\n",
    "_Hinweise/Tipps:_ \n",
    "- Sie müssen die unterschiedlichen Algorithmen nicht (bis zum Maximum) optimieren, hier geht es gerade eher darum zu überprüfen, ob Sie die Algorithmen generell verstanden haben und Sie richtig einsetzen/kombinieren können.\n",
    "- Gucken Sie sich nochmal die besprochenen Algorithmen an und überlegen wo die Stärken und Schwächen liegen.\n",
    "- Sie können selbstverständlich auch unterschiedliche Methoden für die einzelnen Merkmale wählen.  \n",
    "\n",
    "### a) Auswahl der Strategie(n) zum Ersetzen der fehlenden Werte\n",
    "_Punkte: 1_\n",
    "\n",
    "Als erstes müssen Sie sich eine Strategie zum Ersetzen der fehlenden Werte überlegen. Beschreiben Sie diese in der nachfolgenden Markdown-Zeile und begründen Sie, warum Sie diese Strategie gewählt haben. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-wrong",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-tension",
   "metadata": {},
   "source": [
    "### b) Auswahl der Strategie(n) zur Skalierung der Daten\n",
    "_Punkte: 1_\n",
    "\n",
    "Außerdem sollten die Daten skaliert/normalisiert werden. Beschreiben Sie Ihre Strategie und begründen Sie warum Sie diese Strategie bzw. Methoden gewählt haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-contamination",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-communication",
   "metadata": {},
   "source": [
    "### c) Erstellen der Preparation-Pipeline\n",
    "_Punkte: 2_\n",
    "\n",
    "In der nächsten Codezeile können Sie nun die `preparation_pipeline` erstellen. In dieser sollen beide vorherigen Schritte enthalten sein. Sie müssen die Pipeline aber noch nicht \"trainieren\" (Aufruf der Methode `fit()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "# Hier können Sie die weiteren benötigten Imports hinzufügen\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "preparation_pipeline = Pipeline() # IHRE LÖSUNG HIER\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-softball",
   "metadata": {},
   "source": [
    "Warum macht es noch keinen Sinn die Pipeline jetzt schon zu trainieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-premises",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-spyware",
   "metadata": {},
   "source": [
    "__Muster-Antwort:__\n",
    "- Wir haben noch keine separaten Trainings- und Testdatensets und daher würden wir Testdaten zum Training verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-alabama",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Trainingsvorbereitung und Modellauswahl  (4 Punkte)\n",
    "Ihre nächste Aufgabe ist es das Training vorzubereiten und den richtigen ML-Algorithmus auszuwählen. Dafür müssen Sie die folgenden Teilaufgaben erledigen:\n",
    "- a) Erstellen des Test- und Trainingsdatenset\n",
    "- b) Kreuzvalidierung im Trainingsprozess\n",
    "- c) Optimieren eines ML-Algorithmus\n",
    "- d) Testen der trainierten Pipeline\n",
    "\n",
    "### a) Erstellen des Test- und Trainingsdatenset\n",
    "_Punkte: 0,5_\n",
    "\n",
    "Zuerst benötigen wir ein Test- und ein Trainingsdatenset. Das Testdatenset soll 30% der gesamten Daten enthalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data and target from the data frame \n",
    "data = housing_df.loc[:, :'Longitude']\n",
    "target = housing_df['Label']\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# IHRE LÖSUNG HIER\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Die Funktion train_test_split() teilt die gegebenen Parameter in zufälliger Reihenfolge entsprechend der Testgröße.\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, target, test_size = 0.3)\n",
    "\n",
    "#Überprüfen, ob die Größe der Daten korrekt ist.\n",
    "assert round(len(data)*0.3) == len(test_data)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-jones",
   "metadata": {},
   "source": [
    "### b) Kreuzvalidierung im Trainingsprozess\n",
    "_Punkte: 1_\n",
    "\n",
    "Was ist unter Kreuzvalidierung im Trainingsprozess zu verstehen und wieso wird es verwendet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-hampton",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__\n",
    "\n",
    "Durch eine Pipeline können verschiedene Berechnungen verkettet werden, wodurch sie einfacher wiederholt durchzuführen sind. Die Berechnungen können hierbei durch verschiedene Parameter (Hyperparameter) angepasst werden. Da oft die Parameter für die beste Vorhersageperformance nicht bekannt sind, müssen diese durchprobiert werden. <br>\n",
    "Um die Performance zu messen und zu vergleichen wird der Datensatz, der zum Trainieren des ML-Modells genutzt wird, erneut aufgeteilt. Ein Bereich wird weiter für das Training des Modells benutzt, während der Rest zur Validierung genutzt wird. Da die Label-Daten des Validierungsdatensatzes bekannt sind, lässt sich hierraus die Genauigkeit der Vorhersagen berechnen.<br>\n",
    "Ein Problem durch dieses Verfahren ist die Verkleinerung des Trainingsdatensatzes. Dem wird durch die Kreuzvalidierung entgegengewirkt. Der Trainingsdatensatz wird n mal in n-Teile aufgesplittet. Für jeden n-ten Durchgang wird der n-te Teil des Datensatzes als Validierungsdatensatz benutzt, während der verbliebene Datensatz zum Training des Modells genutzt werden kann. Durch die Iteration der verschiedenen Datensätze in Kombination mit den verschiedenen Pipeline-Parametern können die optimalen Parameter herausgefunden werden.\n",
    "\n",
    "Innerhalb Scikit ist die Kreuzvalidierung durch sklearn.model_selection.GridSearchCV möglich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-macintosh",
   "metadata": {},
   "source": [
    "__Muster-Antwort:__\n",
    "- Während des Trainings müssen unterschiedliche Hyperparameter optimiert werden.\n",
    "- Um die optimalen Parameter auswählen zu können, muss auch getestet werden.\n",
    "- Daher wird ein weiteres Datenset benötigt, das sogenannte Validierungsdatenset.\n",
    "- Da dadurch die Daten fürs Training weiter schrumpfen, wurde die Kreuzvalidierung erfunden.\n",
    "- Splitten der Trainingsdaten in $k$ Subsets. Das Netzwerk $k$ mal trainieren und dabei immer mit dem $k$ten Subset testen. Durchschnitt der Testergebnisse ist Gesamtergebnis für eine bestimmte Hyperparameterkombination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-dating",
   "metadata": {},
   "source": [
    "### c) Optimieren eines ML-Algorithmus\n",
    "_Punkte: 1,5_\n",
    "\n",
    "Im nächsten Schritt optimieren wir einen ML-Algorithmus. Da wir ein Klassifikationsproblem lösen wollen, kommen nur Klassifikationsalgorithmen als mögliche Algorithmen in Frage. Wir werden den [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) verwenden. \n",
    "\n",
    "Der `RandomForestClassifier` soll eine maximale Tiefe von 6 haben und maximal 75% der Daten pro Baum verwenden. Setzen Sie den `random_state` auf 0. Für die Anzahl der Bäume sollen die folgenden Werte überprüft werden: `[30, 40, 50, 60, 70, 80]`. Außerdem sollen die beiden Möglichkeiten `['gini', 'entropy']` für das Kriterium, nach dem geteilt wird, getestet werden.\n",
    "\n",
    "Führen Sie die folgenden Schritte durch:\n",
    "- Erstellen Sie eine Pipeline, die zuerst die vorher bereits erstellte Vorverarbeitung durchführt und anschließend den `RandomForestClassifier` aufruft. \n",
    "- Finden Sie die optimalen Parameter aus den angegebenen Parameterbereichen.\n",
    "- Speichern Sie die `Pipeline` mit den besten Parametern in der Variable `trained_pipeline`\n",
    "- Geben Sie die beste `Pipeline` aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Hier können Sie weitere benötigte Importe hinzufügen\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# IHRE LÖSUNG HIER\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-undergraduate",
   "metadata": {},
   "source": [
    "### d) Testen der trainierten Pipeline\n",
    "_Punkte: 1_\n",
    "\n",
    "Nachdem Sie die `Pipeline` trainiert haben, ist es nun Zeit diese zu testen. Lassen Sie sich dafür den Score einmal für das Test- und einmal für das Trainingsdatenset berechnen. Was fällt auf? Welche Metrik wird für das berechnen verwendet bzw. was sagt sie aus? Ist diese Metrik hier sinnvoll?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# IHRE LÖSUNG HIER\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-childhood",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-classic",
   "metadata": {},
   "source": [
    "## Aufgabe 3 - Weitere Evaluierung und Visualisierung (2 Punkte)\n",
    "Im letzten Schritt wollen wir uns die Ergebnisse noch einmal genauer angucken, um eventuell zu verstehen, was passiert ist. Dazu sind die folgenden Teilaufgaben zu erledigen:\n",
    "- a) Erstellen eines Confusion Matrix-Diagramms\n",
    "- b) Analyse des Einfluss des Parameters n_estimators auf das Ergebnis\n",
    "\n",
    "### a) Erstellen eines Confusion Matrix-Diagramms\n",
    "_Punkte: 1_\n",
    "\n",
    "Erstellen Sie mit Hilfe der `plot_confusion_matrix`-Funktion das Diagramm der Confusion Matrix. Analysieren Sie dieses anschließend.\n",
    "\n",
    "_Tipps:_\n",
    "- Welche Klassen wurden falsch klassifiziert?\n",
    "- Was könnten mögliche Gründe dafür sein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# IHRE LÖSUNG HIER\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-proposition",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-kruger",
   "metadata": {},
   "source": [
    "### b) Analyse des Einfluss des Parameters n_estimators auf das Ergebnis\n",
    "_Punkte: 1_\n",
    "\n",
    "Zum Schluss wollen wir noch einmal analysieren welchen Einfluss der Parameter `n_estimators` auf das Trainingsergebnis hat. Verwenden Sie dafür die Funktion `validation_curve`, um für den getesteten Parameterbereich des Parameters die nötigen Daten zu sammeln. Speichern Sie die Rückgabe in den Variablen `train_scores` und `valid_score`. Erstellen Sie außerdem eine Variable `n_estimators`, die alle möglichen Werte für den Parameter enthält. \n",
    "\n",
    "Welche Rückschlüsse lässt das Diagramm zu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# IHRE LÖSUNG HIER\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, calculate the means and standard deviations\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "valid_scores_mean = valid_scores.mean(axis=1)\n",
    "valid_scores_std = valid_scores.std(axis=1)\n",
    "\n",
    "# create the figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Validation Curve of RandomForestClassifier with different n_estimators values\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Score\")\n",
    "# plot the training score\n",
    "plt.plot(n_estimators, train_scores_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.fill_between(n_estimators, \n",
    "                 train_scores_mean - train_scores_std, \n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 color=\"darkorange\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "# plot the validation score\n",
    "plt.plot(n_estimators, valid_scores_mean, label=\"Cross-validation score\", color=\"navy\")\n",
    "plt.fill_between(n_estimators, \n",
    "                 valid_scores_mean - valid_scores_std, \n",
    "                 valid_scores_mean + valid_scores_std, \n",
    "                 color=\"navy\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-wages",
   "metadata": {},
   "source": [
    "__Ihre Antwort:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-digest",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wahlpflichtfach Künstliche Intelligenz II: Praktikum | [Startseite](index.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
